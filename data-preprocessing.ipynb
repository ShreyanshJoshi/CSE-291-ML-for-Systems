{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pymysql\n",
    "import time\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = ['car_1', 'wine_1', 'student_1', 'inn_1', 'flight_1', 'formula_1']\n",
    "curr = \"formula_1\"\n",
    "\n",
    "def get_queries(database):\n",
    "    # Open the JSON file and load its contents\n",
    "    with open(database, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    query_list = []\n",
    "    temp = []\n",
    "    for i in range(len(data)):\n",
    "        variables = data[i]['variables']\n",
    "        sql_queries = data[i]['sql']\n",
    "\n",
    "        # replacing each occurrence of a particular variable in any of the queries\n",
    "        for p, sql_query in enumerate(sql_queries):\n",
    "            sql_queries[p] = sql_query\n",
    "            for var in variables:\n",
    "                sql_queries[p] = sql_queries[p].replace(var['name'], var['example'])\n",
    "            if data[i][\"sentences\"][0][\"database\"] == curr:\n",
    "                query_list.append(sql_queries[p])\n",
    "                temp.append(data[i][\"sentences\"][0][\"database\"])\n",
    "\n",
    "\n",
    "    \n",
    "    cnt = defaultdict(int)\n",
    "    for i in range(len(temp)):\n",
    "        cnt[temp[i]] += 1\n",
    "\n",
    "    print(cnt)\n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'formula_1': 40})\n",
      "defaultdict(<class 'int'>, {'formula_1': 40})\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "all_queries = []\n",
    "\n",
    "# all_queries.extend(get_queries(\"./atis.json\"))\n",
    "queries = dict()\n",
    "\n",
    "import os\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith('spider.json'):\n",
    "        all_queries.extend(get_queries(f'./{filename}'))\n",
    "        queries[filename] = get_queries(f'./{filename}')\n",
    "\n",
    "        \n",
    "\n",
    "print(len(all_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spider.json: 40\n"
     ]
    }
   ],
   "source": [
    "len(all_queries)\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.endswith('spider.json'):\n",
    "        print(f'{filename}: {len(queries[filename])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customers_and_addresses', 'manufacturer', 'medicine_enzyme_interaction', 'climbing', 'customers_campaigns_ecommerce', 'geo', 'department_store', 'scholar', 'riding_club', 'device', 'club_1', 'department_management', 'cre_Theme_park', 'wedding', 'behavior_monitoring', 'journal_committee', 'train_station', 'game_injury', 'flight_2', 'product_catalog', 'company_employee', 'county_public_safety', 'phone_market', 'hr_1', 'assets_maintenance', 'sakila_1', 'race_track', 'tracking_orders', 'small_bank_1', 'college_1', 'orchestra', 'hospital_1', 'performance_attendance', 'customer_complaints', 'company_1', 'pets_1', 'tracking_software_problems', 'workshop_paper', 'company_office', 'apartment_rentals', 'machine_repair', 'flight_1', 'music_2', 'customers_card_transactions', 'local_govt_and_lot', 'shop_membership', 'party_people', 'network_1', 'wta_1', 'election', 'document_management', 'poker_player', 'scientist_1', 'museum_visit', 'products_for_hire', 'movie_1', 'news_report', 'game_1', 'school_finance', 'student_assessment', 'insurance_fnol', 'local_govt_mdm', 'allergy_1', 'entrepreneur', 'storm_record', 'phone_1', 'restaurant_1', 'employee_hire_evaluation', 'concert_singer', 'election_representative', 'theme_gallery', 'cre_Docs_and_Epenses', 'singer', 'imdb', 'book_2', 'products_gen_characteristics', 'mountain_photos', 'aircraft', 'insurance_policies', 'school_bus', 'music_1', 'film_rank', 'college_3', 'program_share', 'swimming', 'college_2', 'cre_Drama_Workshop_Groups', 'gymnast', 'local_govt_in_alabama', 'sports_competition', 'voter_2', 'world_1', 'flight_4', 'yelp', 'station_weather', 'icfp_1', 'customers_and_invoices', 'perpetrator', 'gas_company', 'roller_coaster', 'culture_company', 'school_player', 'baseball_1', 'inn_1', 'car_1', 'tracking_grants_for_research', 'architecture', 'party_host', 'customers_and_products_contacts', 'tracking_share_transactions', 'course_teach', 'coffee_shop', 'dog_kennels', 'wrestler', 'musical', 'browser_web', 'entertainment_awards', 'match_season', 'farm', 'loan_1', 'student_transcripts_tracking', 'epinions_1', 'chinook_1', 'e_government', 'university_basketball', 'csu_1', 'real_estate_properties', 'student_1', 'store_product', 'wine_1', 'restaurants', 'soccer_1', 'music_4', 'soccer_2', 'protein_institute', 'flight_company', 'manufactory_1', 'decoration_competition', 'store_1', 'voter_1', 'driving_school', 'tvshow', 'activity_1', 'cre_Doc_Control_Systems', 'dorm_1', 'railway', 'customer_deliveries', 'body_builder', 'debate', 'formula_1', 'twitter_1', 'ship_1', 'cre_Doc_Template_Mgt', 'battle_death', 'bike_1', 'ship_mission', 'network_2', 'insurance_and_eClaims', 'cinema', 'academic', 'cre_Doc_Tracking_DB', 'city_record', 'solvency_ii', 'pilot_record', 'e_learning', 'candidate_poll'}\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "s = set()\n",
    "with open('./spider.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    sentences = data[i][\"sentences\"]\n",
    "    for sentence in sentences:\n",
    "        s.add(sentence[\"database\"])\n",
    "\n",
    "print(s)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['query'])\n",
    "    for query in all_queries:\n",
    "        writer.writerow([query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining execution time\n",
    "\n",
    "At this point, we have all the queries. Now, we write a script to run the queries one by one and store their execution times in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to the database\n",
    "# connection = pymysql.connect(\n",
    "#     host='localhost',\n",
    "#     user='root',\n",
    "#     password=''\n",
    "# )\n",
    "\n",
    "import sqlite3\n",
    "sqlite_file = f'/mnt/d/Documents/UCSD/Courses/CSE 291 Virt/temp/data/{curr}.sqlite'\n",
    "\n",
    "connection = sqlite3.connect(sqlite_file)\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"DATABASE\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23463/3662751665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'CREATE DATABASE IF NOT EXISTS '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: near \"DATABASE\": syntax error"
     ]
    }
   ],
   "source": [
    "cursor.execute(f'CREATE DATABASE IF NOT EXISTS ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \".\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1380/2968861642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".tables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \".\": syntax error"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SHOW TABLES\")\n",
    "tables = cursor.fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Connection.commit()>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.connection.commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.csv', newline='') as csvfile:\n",
    "    query_reader = csv.reader(csvfile)\n",
    "    rows = list(query_reader)\n",
    "\n",
    "# Add header for the \"running time\" column\n",
    "rows[0].append('running time')\n",
    "\n",
    "for row in rows[1:]:\n",
    "    start_time = time.time()\n",
    "    sql_query = row[0]\n",
    "    cursor.execute(sql_query)\n",
    "    cursor.connection.commit()\n",
    "    end_time = time.time()\n",
    "    running_time = (end_time - start_time) * 1000\n",
    "    row.append(str(running_time) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./queries_with_running_time.csv', 'w', newline='') as csvfile:\n",
    "    query_writer = csv.writer(csvfile)\n",
    "    query_writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
